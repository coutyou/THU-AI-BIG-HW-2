{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:18:38.760473Z",
     "start_time": "2019-12-18T22:18:37.336975Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset, random_split\n",
    "from torchvision import transforms, models, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.helper import predefined_split\n",
    "%matplotlib inline\n",
    "torch.__version__\n",
    "\n",
    "from itertools import islice\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:18:38.956672Z",
     "start_time": "2019-12-18T22:18:38.946758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f43901876b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 60\n",
    "DEVICE_NUM = 1\n",
    "LR = 0.01\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 0\n",
    "torch.manual_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:18:39.289046Z",
     "start_time": "2019-12-18T22:18:39.116358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(DEVICE_NUM)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:18:39.509817Z",
     "start_time": "2019-12-18T22:18:39.505231Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:18:39.748680Z",
     "start_time": "2019-12-18T22:18:39.729672Z"
    }
   },
   "outputs": [],
   "source": [
    "train_images = np.load(\"train.npy\")\n",
    "test_images = np.load(\"test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:18:40.191194Z",
     "start_time": "2019-12-18T22:18:40.172148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_df = pd.read_csv(\"train.csv\")\n",
    "train_labels = train_labels_df[\"label\"].to_numpy()\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:18:40.504269Z",
     "start_time": "2019-12-18T22:18:40.497590Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte'\n",
    "                               % kind)\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II',\n",
    "                                 lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath,\n",
    "                             dtype=np.uint8)\n",
    "\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII',\n",
    "                                               imgpath.read(16))\n",
    "        images = np.fromfile(imgpath,\n",
    "                             dtype=np.uint8).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T13:37:04.943297Z",
     "start_time": "2019-12-18T13:37:04.830911Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"./\"\n",
    "train_images_ex, train_labels_ex  = load_mnist(data_path, kind=\"train\")\n",
    "test_images_ex, test_labels_ex  =  load_mnist(data_path, kind=\"t10k\")\n",
    "\n",
    "train_images_ex = np.concatenate((train_images_ex,test_images_ex),axis=0)\n",
    "train_labels_ex = np.concatenate((train_labels_ex,test_labels_ex),axis=0)\n",
    "\n",
    "train_images = np.concatenate((train_images_ex,train_images),axis=0)\n",
    "train_labels = np.concatenate((train_labels_ex,train_labels),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T13:37:15.982722Z",
     "start_time": "2019-12-18T13:37:15.976419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T13:37:24.101668Z",
     "start_time": "2019-12-18T13:37:24.096954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T13:37:48.034213Z",
     "start_time": "2019-12-18T13:37:46.874720Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images,train_labels,test_size=0.05, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:18:46.580288Z",
     "start_time": "2019-12-18T22:18:46.564114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>4999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id  label\n",
       "0            0      0\n",
       "1            1      0\n",
       "2            2      0\n",
       "3            3      0\n",
       "4            4      0\n",
       "...        ...    ...\n",
       "4995      4995      0\n",
       "4996      4996      0\n",
       "4997      4997      0\n",
       "4998      4998      0\n",
       "4999      4999      0\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(\"samplesummission.csv\")\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Img Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T13:42:48.609813Z",
     "start_time": "2019-12-18T13:41:26.237523Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# from skimage import color\n",
    "# from skimage.morphology import disk\n",
    "# import skimage.filters.rank as sfr\n",
    "\n",
    "# for i in range(10):\n",
    "#     path = \"./data/train/\"+str(i)\n",
    "#     if not os.path.exists(path):\n",
    "#         os.mkdir(path)\n",
    "#     path = \"./data/val/\"+str(i)\n",
    "#     if not os.path.exists(path):\n",
    "#         os.mkdir(path)\n",
    "        \n",
    "# path = \"./data/test/\"+str(0)\n",
    "# if not os.path.exists(path):\n",
    "#     os.mkdir(path)\n",
    "\n",
    "\n",
    "# for index,A in enumerate(train_images):\n",
    "#     A = A.reshape(28,28)\n",
    "#     A = sfr.median(A, disk(1))\n",
    "#     img = Image.fromarray(A)\n",
    "#     img.save(\"./data/train/\"+str(train_labels[index])+\"/\"+str(index)+\".jpg\")\n",
    "    \n",
    "# for index,A in enumerate(val_images):\n",
    "#     A = A.reshape(28,28)\n",
    "#     A = sfr.median(A, disk(1))\n",
    "#     img = Image.fromarray(A)\n",
    "#     img.save(\"./data/val/\"+str(val_labels[index])+\"/\"+str(index)+\".jpg\")\n",
    "\n",
    "# for index,A in enumerate(test_images):\n",
    "#     A = A.reshape(28,28)\n",
    "#     A = sfr.median(A, disk(1))\n",
    "#     img = Image.fromarray(A)\n",
    "#     if index < 10:\n",
    "#         img.save(\"./data/test/\"+str(0)+\"/000\"+str(index)+\".jpg\")\n",
    "#     elif index < 100:\n",
    "#         img.save(\"./data/test/\"+str(0)+\"/00\"+str(index)+\".jpg\")\n",
    "#     elif index < 1000:\n",
    "#         img.save(\"./data/test/\"+str(0)+\"/0\"+str(index)+\".jpg\")\n",
    "#     else:\n",
    "#         img.save(\"./data/test/\"+str(0)+\"/\"+str(index)+\".jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:18:53.932070Z",
     "start_time": "2019-12-18T22:18:53.303436Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_dir = '/home/yj-dyj/AI_homework/data'\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_ds = datasets.ImageFolder(\n",
    "    os.path.join(data_dir, 'train'), train_transforms)\n",
    "val_ds = datasets.ImageFolder(\n",
    "    os.path.join(data_dir, 'val'), val_transforms)\n",
    "test_ds = datasets.ImageFolder(\n",
    "    os.path.join(data_dir, 'test'), test_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:18:56.618900Z",
     "start_time": "2019-12-18T22:18:56.612668Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, output_features):\n",
    "        super().__init__()\n",
    "        model = models.resnet34(pretrained=True)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, output_features)\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:18:57.122505Z",
     "start_time": "2019-12-18T22:18:57.117610Z"
    }
   },
   "outputs": [],
   "source": [
    "from skorch.callbacks import LRScheduler\n",
    "\n",
    "lrscheduler = LRScheduler(\n",
    "    policy='StepLR', step_size=10, gamma=0.05)\n",
    "\n",
    "from skorch.callbacks import Checkpoint\n",
    "\n",
    "checkpoint = Checkpoint(\n",
    "    f_params='best_model.pt', monitor='valid_acc_best')\n",
    "    \n",
    "# from skorch.callbacks import Freezer\n",
    "\n",
    "# freezer = Freezer(lambda x: not x.startswith('model.fc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:18:57.461162Z",
     "start_time": "2019-12-18T22:18:57.455827Z"
    }
   },
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    Net, \n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    lr=LR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_epochs=EPOCHS,\n",
    "    module__output_features=10,\n",
    "    optimizer=optim.SGD,\n",
    "    optimizer__momentum=MOMENTUM,\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_train__num_workers=4,\n",
    "    iterator_valid__shuffle=True,\n",
    "    iterator_valid__num_workers=4,\n",
    "    callbacks=[lrscheduler, checkpoint],\n",
    "    train_split=predefined_split(val_ds),\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T20:04:12.008161Z",
     "start_time": "2019-12-18T16:15:27.705437Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ------------  -----------  ------------  ----  --------\n",
      "      1        \u001b[36m0.3711\u001b[0m       \u001b[32m0.9086\u001b[0m        \u001b[35m0.2464\u001b[0m     +  292.6983\n",
      "      2        \u001b[36m0.2509\u001b[0m       0.9032        0.2670        222.6787\n",
      "      3        \u001b[36m0.2187\u001b[0m       \u001b[32m0.9208\u001b[0m        \u001b[35m0.2111\u001b[0m     +  226.9561\n",
      "      4        \u001b[36m0.1968\u001b[0m       \u001b[32m0.9306\u001b[0m        \u001b[35m0.1914\u001b[0m     +  222.4645\n",
      "      5        \u001b[36m0.1818\u001b[0m       0.9250        0.2071        223.3307\n",
      "      6        \u001b[36m0.1683\u001b[0m       \u001b[32m0.9328\u001b[0m        \u001b[35m0.1789\u001b[0m     +  221.8302\n",
      "      7        \u001b[36m0.1567\u001b[0m       \u001b[32m0.9384\u001b[0m        \u001b[35m0.1642\u001b[0m     +  221.2316\n",
      "      8        \u001b[36m0.1476\u001b[0m       0.9292        0.1908        221.5709\n",
      "      9        \u001b[36m0.1371\u001b[0m       0.9316        0.1990        221.5526\n",
      "     10        \u001b[36m0.1288\u001b[0m       0.9370        0.1716        221.0359\n",
      "     11        \u001b[36m0.1228\u001b[0m       0.9272        0.2017        220.7543\n",
      "     12        \u001b[36m0.0814\u001b[0m       \u001b[32m0.9514\u001b[0m        \u001b[35m0.1532\u001b[0m     +  224.1046\n",
      "     13        \u001b[36m0.0674\u001b[0m       0.9508        0.1553        221.8014\n",
      "     14        \u001b[36m0.0623\u001b[0m       \u001b[32m0.9524\u001b[0m        \u001b[35m0.1519\u001b[0m     +  221.7104\n",
      "     15        \u001b[36m0.0577\u001b[0m       \u001b[32m0.9526\u001b[0m        0.1543     +  221.5817\n",
      "     16        \u001b[36m0.0540\u001b[0m       0.9510        0.1552        221.2549\n",
      "     17        \u001b[36m0.0518\u001b[0m       \u001b[32m0.9528\u001b[0m        0.1576     +  220.6960\n",
      "     18        \u001b[36m0.0487\u001b[0m       \u001b[32m0.9534\u001b[0m        0.1598     +  221.2154\n",
      "     19        \u001b[36m0.0468\u001b[0m       0.9524        0.1613        220.9894\n",
      "     20        \u001b[36m0.0441\u001b[0m       0.9522        0.1636        224.2711\n",
      "     21        \u001b[36m0.0428\u001b[0m       0.9520        0.1654        221.6785\n",
      "     22        \u001b[36m0.0388\u001b[0m       0.9534        0.1666        221.2121\n",
      "     23        \u001b[36m0.0379\u001b[0m       0.9534        0.1629        220.8809\n",
      "     24        0.0381       0.9532        0.1637        221.1727\n",
      "     25        0.0389       0.9522        0.1637        221.1853\n",
      "     26        \u001b[36m0.0378\u001b[0m       \u001b[32m0.9538\u001b[0m        0.1626     +  221.2971\n",
      "     27        \u001b[36m0.0376\u001b[0m       0.9526        0.1626        220.8452\n",
      "     28        0.0380       0.9534        0.1632        222.4314\n",
      "     29        0.0380       0.9536        0.1617        225.1951\n",
      "     30        \u001b[36m0.0369\u001b[0m       0.9520        0.1647        221.4671\n",
      "     31        0.0379       0.9528        0.1638        221.6088\n",
      "     32        0.0369       0.9536        0.1625        222.3654\n",
      "     33        0.0374       0.9538        0.1621        222.0209\n",
      "     34        0.0380       0.9524        0.1655        221.6907\n",
      "     35        \u001b[36m0.0367\u001b[0m       0.9534        0.1655        222.5451\n",
      "     36        0.0373       0.9532        0.1641        221.4156\n",
      "     37        0.0368       0.9532        0.1631        224.6459\n",
      "     38        0.0373       0.9526        0.1669        221.6355\n",
      "     39        0.0374       0.9528        0.1648        221.8973\n",
      "     40        0.0371       0.9532        0.1637        222.3758\n",
      "     41        0.0376       \u001b[32m0.9544\u001b[0m        0.1634     +  222.1217\n",
      "     42        0.0377       0.9534        0.1646        221.7675\n",
      "     43        0.0370       0.9532        0.1638        221.1496\n",
      "     44        0.0383       0.9530        0.1652        220.9954\n",
      "     45        0.0373       0.9534        0.1640        222.8957\n",
      "     46        0.0367       0.9532        0.1635        222.6214\n",
      "     47        0.0377       0.9538        0.1638        221.0780\n",
      "     48        0.0374       0.9536        0.1642        220.8532\n",
      "     49        0.0374       0.9526        0.1654        220.7169\n",
      "     50        0.0377       0.9542        0.1639        220.8217\n",
      "     51        0.0370       0.9530        0.1643        220.9358\n",
      "     52        0.0378       0.9532        0.1649        220.6498\n",
      "     53        0.0368       \u001b[32m0.9546\u001b[0m        0.1631     +  220.8606\n",
      "     54        0.0377       0.9528        0.1653        222.8513\n",
      "     55        0.0376       0.9542        0.1617        220.5920\n",
      "     56        0.0368       0.9518        0.1654        220.4721\n",
      "     57        0.0373       0.9524        0.1637        221.7955\n",
      "     58        0.0368       0.9540        0.1627        220.9347\n",
      "     59        0.0368       0.9528        0.1658        221.8993\n",
      "     60        0.0381       0.9528        0.1651        220.9311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=Net(\n",
       "    (model): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (5): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       "    )\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(train_ds, y=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:19:20.846666Z",
     "start_time": "2019-12-18T22:19:20.843214Z"
    }
   },
   "outputs": [],
   "source": [
    "val_loader = DataLoader(dataset=val_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_ds, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:19:29.304996Z",
     "start_time": "2019-12-18T22:19:22.460451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net(10).to(DEVICE)\n",
    "model.load_state_dict(torch.load(\"best_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:19:48.793644Z",
     "start_time": "2019-12-18T22:19:31.736487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证集上准确率: 95.0000 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in val_loader:\n",
    "    labels = torch.squeeze(labels)\n",
    "    images = images.type(torch.FloatTensor).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs =  model(images).cpu()\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "print('验证集上准确率: %.4f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:20:13.225798Z",
     "start_time": "2019-12-18T22:19:55.817819Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "res = np.array([])\n",
    "res.dtype = np.int64\n",
    "for images, labels in test_loader:\n",
    "    images = images.type(torch.FloatTensor).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images).cpu()\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    res = np.concatenate((res,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:20:14.706390Z",
     "start_time": "2019-12-18T22:20:14.694693Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4995</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4996</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4997</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4998</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>4999</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id  label\n",
       "0            0      7\n",
       "1            1      6\n",
       "2            2      4\n",
       "3            3      8\n",
       "4            4      1\n",
       "...        ...    ...\n",
       "4995      4995      2\n",
       "4996      4996      5\n",
       "4997      4997      3\n",
       "4998      4998      7\n",
       "4999      4999      3\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = pd.DataFrame(res)\n",
    "submission[\"label\"] = res_df\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:20:16.260384Z",
     "start_time": "2019-12-18T22:20:15.897083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f43268d35d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "\n",
    "fig,axes = plt.subplots(nrows=1,ncols=1,figsize=(15,8))\n",
    "plt.xticks(fontsize=25)\n",
    "plt.yticks(fontsize=25)\n",
    "sb.countplot(y='label', data=submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-18T22:20:17.593767Z",
     "start_time": "2019-12-18T22:20:17.572783Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"transfer.csv\",index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch Env",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "213.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "452px",
    "left": "773px",
    "right": "20px",
    "top": "138px",
    "width": "436px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
